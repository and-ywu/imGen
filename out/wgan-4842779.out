Wed Jul 24 22:09:51 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.145                Driver Version: 384.145                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
| 49%   82C    P2   223W / 250W |   1297MiB / 11172MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |
| 23%   36C    P0    61W / 250W |      0MiB / 11172MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |
| 44%   74C    P2   215W / 250W |   1297MiB / 11172MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |
| 42%   70C    P2   210W / 250W |  10785MiB / 11172MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     14769      C   ...vargiu/local/SL7/amber18/bin/pmemd.cuda  1287MiB |
|    2     15177      C   ...vargiu/local/SL7/amber18/bin/pmemd.cuda  1287MiB |
|    3      5965      C   python3                                    10767MiB |
+-----------------------------------------------------------------------------+
2019-07-24 22:10:10.826921: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-24 22:10:12.141401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-07-24 22:10:12.141444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-07-24 22:10:12.485627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-24 22:10:12.485674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-07-24 22:10:12.485684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-07-24 22:10:12.486615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
Using TensorFlow backend.
/global/home/users/andy-wu/.local/lib/python3.6/site-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
  'Discrepancy between trainable weights and collected trainable'
Model: "generator"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 8192)              2465792   
_________________________________________________________________
reshape_1 (Reshape)          (None, 8, 8, 128)         0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 16, 16, 128)       262272    
_________________________________________________________________
batch_normalization_1 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_1 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 128)       262272    
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_2 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 32, 64)        131136    
_________________________________________________________________
batch_normalization_3 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 32, 32, 64)        65600     
_________________________________________________________________
batch_normalization_4 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
activation_4 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 64, 64, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 64, 64, 32)        32800     
_________________________________________________________________
batch_normalization_5 (Batch (None, 64, 64, 32)        128       
_________________________________________________________________
activation_5 (Activation)    (None, 64, 64, 32)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 64, 64, 1)         513       
_________________________________________________________________
activation_6 (Activation)    (None, 64, 64, 1)         0         
=================================================================
Total params: 3,222,049
Trainable params: 3,221,217
Non-trainable params: 832
_________________________________________________________________
Model: "discriminator"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 32, 32, 64)        640       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     
_________________________________________________________________
batch_normalization_6 (Batch (None, 16, 16, 64)        256       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 16, 16, 128)       73856     
_________________________________________________________________
batch_normalization_7 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 16, 16, 256)       295168    
_________________________________________________________________
batch_normalization_8 (Batch (None, 16, 16, 256)       1024      
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 256)       0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 16, 16, 256)       0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 16, 16, 512)       1180160   
_________________________________________________________________
batch_normalization_9 (Batch (None, 16, 16, 512)       2048      
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 16, 16, 512)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 131072)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 131073    
=================================================================
Total params: 1,721,665
Trainable params: 1,719,745
Non-trainable params: 1,920
_________________________________________________________________
0 [D: 77.106644] [G: 1.422451]
200 [D: -14.702327] [G: -2.461471]
400 [D: -2.581468] [G: -2.773234]
600 [D: 1.288691] [G: 1.236750]
800 [D: -0.015999] [G: 0.438505]
1000 [D: -0.320492] [G: 0.922956]
1200 [D: -0.956889] [G: -0.650016]
1400 [D: -0.554412] [G: -0.243330]
1600 [D: -0.939102] [G: 0.549667]
1800 [D: -0.297320] [G: -1.878358]
2000 [D: -0.894938] [G: -0.305040]
2200 [D: -0.639393] [G: 1.583190]
2400 [D: -0.483455] [G: 0.492088]
2600 [D: -0.317840] [G: 1.344027]
2800 [D: -0.240046] [G: -0.152373]
3000 [D: -0.565796] [G: 1.171918]
3200 [D: -0.512632] [G: 0.107594]
3400 [D: 0.473735] [G: 3.640408]
3600 [D: -0.928646] [G: 1.906634]
3800 [D: -0.194571] [G: 3.473738]
4000 [D: 0.558173] [G: 4.260971]
4200 [D: -0.568296] [G: 3.282298]
4400 [D: -0.286624] [G: -0.110517]
4600 [D: 0.137612] [G: 0.080786]
4800 [D: -0.648901] [G: 3.370721]
5000 [D: -0.822285] [G: 1.672953]
5200 [D: -0.713827] [G: 1.454726]
5400 [D: 0.562439] [G: -1.803412]
5600 [D: -0.241615] [G: 3.072331]
5800 [D: -0.882567] [G: 1.789982]
6000 [D: -0.271541] [G: -3.480803]
6200 [D: -0.011476] [G: 0.983843]
6400 [D: 0.017356] [G: -2.320172]
6600 [D: -0.167476] [G: 1.615310]
6800 [D: -0.335797] [G: -1.102569]
7000 [D: 0.964966] [G: -0.147180]
7200 [D: -0.674861] [G: -0.124665]
7400 [D: -3.500126] [G: -3.368516]
7600 [D: -2.742834] [G: 1.389019]
7800 [D: -0.193550] [G: 3.629264]
8000 [D: -1.207685] [G: -0.785808]
8200 [D: 0.150849] [G: -1.656223]
8400 [D: -0.467850] [G: 0.729521]
8600 [D: -0.385317] [G: -1.485584]
8800 [D: -2.179249] [G: -2.948689]
9000 [D: -0.859336] [G: -3.417723]
9200 [D: 0.136017] [G: -3.017485]
9400 [D: -0.468686] [G: -3.585181]
9600 [D: -0.235172] [G: -0.344589]
9800 [D: -0.607116] [G: -1.535949]
10000 [D: -0.376345] [G: -1.883851]
