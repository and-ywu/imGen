Wed Jul 24 01:10:46 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.145                Driver Version: 384.145                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
| 50%   84C    P2   200W / 250W |   1297MiB / 11172MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |
| 23%   39C    P0    62W / 250W |      0MiB / 11172MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |
| 48%   81C    P2   223W / 250W |   1297MiB / 11172MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |
| 23%   37C    P0    60W / 250W |      0MiB / 11172MiB |      2%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     14769      C   ...vargiu/local/SL7/amber18/bin/pmemd.cuda  1287MiB |
|    2     15177      C   ...vargiu/local/SL7/amber18/bin/pmemd.cuda  1287MiB |
+-----------------------------------------------------------------------------+
2019-07-24 01:10:58.615673: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-24 01:11:01.411551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-07-24 01:11:01.411599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-07-24 01:11:01.791935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-24 01:11:01.791980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-07-24 01:11:01.791990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-07-24 01:11:01.792914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
Using TensorFlow backend.
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 8192)              2465792   
_________________________________________________________________
reshape_1 (Reshape)          (None, 8, 8, 128)         0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 16, 16, 128)       262272    
_________________________________________________________________
batch_normalization_1 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_1 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 128)       262272    
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
activation_2 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 32, 32, 64)        131136    
_________________________________________________________________
batch_normalization_3 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 64, 64, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 64, 64, 64)        65600     
_________________________________________________________________
batch_normalization_4 (Batch (None, 64, 64, 64)        256       
_________________________________________________________________
activation_4 (Activation)    (None, 64, 64, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 64, 64, 1)         1025      
_________________________________________________________________
activation_5 (Activation)    (None, 64, 64, 1)         0         
=================================================================
Total params: 3,189,633
Trainable params: 3,188,865
Non-trainable params: 768
_________________________________________________________________
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 32, 32, 32)        320       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 17, 17, 64)        0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 17, 17, 64)        256       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 17, 17, 64)        0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 128)         73856     
_________________________________________________________________
zero_padding2d_2 (ZeroPaddin (None, 10, 10, 128)       0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 10, 10, 128)       512       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 128)       0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 10, 10, 128)       0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 10, 10, 256)       295168    
_________________________________________________________________
batch_normalization_7 (Batch (None, 10, 10, 256)       1024      
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 10, 10, 256)       0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 10, 10, 256)       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 10, 10, 512)       1180160   
_________________________________________________________________
batch_normalization_8 (Batch (None, 10, 10, 512)       2048      
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 10, 10, 512)       0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 10, 10, 512)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 51200)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 51201     
=================================================================
Total params: 1,623,041
Trainable params: 1,621,121
Non-trainable params: 1,920
_________________________________________________________________
0 [D: 60.053425] [G: 0.337356]
200 [D: -1.622104] [G: 3.188547]
400 [D: -0.968812] [G: 1.585352]
600 [D: -1.568354] [G: 2.301541]
800 [D: -0.700105] [G: 1.775733]
1000 [D: -0.681025] [G: 0.293878]
1200 [D: -0.052540] [G: 0.234723]
1400 [D: -0.271643] [G: 0.000519]
1600 [D: 0.156966] [G: 1.415335]
1800 [D: -0.722025] [G: 0.212860]
2000 [D: -0.103597] [G: -2.170352]
2200 [D: -0.438392] [G: 1.296931]
2400 [D: -0.308206] [G: -2.147728]
2600 [D: -0.102092] [G: -2.067143]
2800 [D: -0.293671] [G: -2.821172]
3000 [D: -1.806426] [G: -0.469872]
3200 [D: 0.582911] [G: -2.576075]
3400 [D: -0.601400] [G: -4.025848]
3600 [D: -1.177330] [G: -3.433336]
3800 [D: -0.297050] [G: -4.419687]
4000 [D: -0.532138] [G: -2.329228]
4200 [D: -0.813122] [G: -2.359177]
4400 [D: -1.490857] [G: -2.331511]
4600 [D: -0.963744] [G: -4.488930]
4800 [D: -0.293825] [G: -0.936934]
5000 [D: -0.714303] [G: -3.795400]
5200 [D: -0.166397] [G: -3.118301]
5400 [D: -0.530326] [G: -5.058933]
5600 [D: -1.588971] [G: -2.825493]
5800 [D: 0.004293] [G: -2.983868]
6000 [D: -0.850008] [G: -3.739815]
6200 [D: -0.193043] [G: -2.985785]
6400 [D: -1.885635] [G: -2.964771]
6600 [D: -1.114629] [G: -2.241103]
6800 [D: -2.429266] [G: -4.133867]
7000 [D: -1.244991] [G: -3.926073]
7200 [D: -0.680344] [G: -4.963600]
7400 [D: -0.439911] [G: -4.455605]
7600 [D: -1.669898] [G: -4.618363]
7800 [D: -1.829579] [G: -5.199502]
8000 [D: -0.361247] [G: -8.189067]
8200 [D: -0.711296] [G: -5.835458]
8400 [D: -0.841167] [G: -5.941721]
8600 [D: -0.130493] [G: -5.157475]
8800 [D: 0.106687] [G: -5.400440]
9000 [D: 1.097717] [G: -7.318644]
9200 [D: -0.072320] [G: -5.404665]
9400 [D: -0.366775] [G: -5.718072]
9600 [D: -1.036680] [G: -6.909002]
9800 [D: -0.386050] [G: -7.398857]
10000 [D: -0.236194] [G: -7.784113]
10200 [D: -0.449505] [G: -8.410180]
10400 [D: -0.756748] [G: -11.849520]
10600 [D: -0.752257] [G: -13.351255]
10800 [D: -1.511633] [G: -12.752281]
11000 [D: -0.882765] [G: -16.305868]
11200 [D: -0.708305] [G: -13.228632]
11400 [D: -0.139541] [G: -12.190554]
11600 [D: -1.223104] [G: -13.449623]
11800 [D: -0.089071] [G: -15.691715]
12000 [D: -2.083060] [G: -15.274181]
12200 [D: -0.617749] [G: -15.254354]
12400 [D: -0.554061] [G: -15.377829]
12600 [D: -0.498661] [G: -16.494614]
12800 [D: -1.612390] [G: -16.375786]
13000 [D: -0.503103] [G: -14.756173]
13200 [D: -0.812350] [G: -16.050644]
13400 [D: -0.679741] [G: -15.999011]
13600 [D: -1.811937] [G: -15.478591]
13800 [D: -1.081179] [G: -16.823341]
14000 [D: -0.001494] [G: -17.134497]
14200 [D: -0.399885] [G: -15.840577]
14400 [D: -1.615578] [G: -16.669882]
14600 [D: -0.934057] [G: -16.016724]
14800 [D: -0.378341] [G: -13.704089]
15000 [D: -0.676038] [G: -17.959148]
15200 [D: -0.514339] [G: -15.929541]
15400 [D: -0.885137] [G: -19.471638]
15600 [D: -1.960729] [G: -17.987442]
15800 [D: -1.309952] [G: -18.042791]
16000 [D: -0.329781] [G: -18.601480]
16200 [D: -0.964281] [G: -17.398235]
16400 [D: 0.454787] [G: -19.363880]
16600 [D: 0.322890] [G: -20.513708]
16800 [D: -1.095399] [G: -21.183241]
17000 [D: 0.191965] [G: -19.963375]
17200 [D: -0.993863] [G: -19.647348]
17400 [D: -1.134478] [G: -22.264286]
17600 [D: -0.664507] [G: -24.666409]
17800 [D: -0.824362] [G: -21.871456]
18000 [D: 0.115824] [G: -23.360096]
18200 [D: -0.430571] [G: -21.409210]
18400 [D: 0.029402] [G: -23.374779]
18600 [D: -0.825262] [G: -23.613623]
18800 [D: -0.502396] [G: -21.076616]
19000 [D: 1.214017] [G: -24.822994]
19200 [D: 0.332576] [G: -25.869434]
19400 [D: -0.288473] [G: -25.596767]
19600 [D: -0.652554] [G: -27.381454]
19800 [D: -1.532331] [G: -26.506891]
20000 [D: 0.115981] [G: -26.896908]
